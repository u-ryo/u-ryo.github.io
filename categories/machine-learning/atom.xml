<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><title><![CDATA[u-ryo's blog]]></title><link href="http://u-ryo.github.io//categories/machine-learning/atom.xml" rel="self"/><link href="http://u-ryo.github.io//"/><updated>2017-08-22T10:04:50+09:00</updated><id>http://u-ryo.github.io//</id><author><name><![CDATA[u-ryo]]></name></author><generator uri="http://sysgears.com/grain/">Grain</generator><entry><title type="html"><![CDATA[RapidMiner]]></title><link href="http://u-ryo.github.io//blog/2018/05/11/rapidminer/"/><updated>2018-05-11T17:25:36+09:00</updated><id>/blog/2018/05/11/rapidminer/</id><content type="html"><![CDATA[<p>今、会社の業務の一部(先月から0.75)でAI、機械学習をやっています。
題材として<a href="http://signate.jp/">Signate</a>の
<a href="https://signate.jp/competitions/1">【練習問題】銀行の顧客ターゲティング</a>
をやっています。
業務時間中に色々試せるのはありがたいです。
PythonやR、kerasや<a href="https://colab.research.google.com/">Google Colaboratory</a>や
Azure上のVM with GPUとか貰って試していたのですが、
結局<a href="http://rapidminer.com/">RapidMiner</a>使ってみました。
<a href="https://www.rapidminer.jp/2016/07/07/【連載】rapidminerで始めるデータ分析～part5：予測モデル/">KSKのtutorial</a>で勉強して、
色々と回せるようになりました。
確かに簡単ですねこれ。
でも、分かって来るとその限界や欠点も見えてきました。
また、課題に対する知見も溜まってきたので、忘れないうちに。</p>
<ul>
<li>基本的な流れは、<code>Read CSV(train.csv)</code>→<code>Cross Validation</code>(<code>Gradient Boosted Trees</code>→<code>Apply Model</code>→<code>Performance(Binominal Classification)</code>)と<code>Read CSV(test.csv)</code>を合わせて→<code>Apply Model</code>→<code>Select Atributes</code>→<code>Write CSV</code><img src="rapidminer1.png" alt="RapidMiner flow" /> <img src="rapidminer2.png" alt="inside cross validation" /></li>
<li>CSVのreadでは、まず最初の列のidを<code>id</code>、最後のyを<code>label</code>に指定、その他のattributesについては、yes/no 2値のものを<code>binominal</code>、dayを<code>integer</code>ではなく<code>polynominal</code>にするのがpointか。</li>
<li>dayとmonthから日付にしては? と思っていたのだが、pdateを見ると同じ月日でも何百日のものもあって複数yearsありそう、且つyearは特定できなさそう(365日毎でもない)</li>
<li>ならいっそday/monthをfeatureから落とすと精度が落ちる</li>
<li>せめてmonthだけでも<code>date</code>として認識できないかと試したがdate format指定を<code>mmm</code>では出来なかった(小文字だから?)</li>
<li>ウリのAutoModelを試したところ、data file指定、fieldsのcorrelationから落とすattributesを指定、複数種類のmodelを実行、その後modelのparameterをいじれてsimulationが出来、modelに対する理解が進むというもの。AutoModelではGBoostよりDeepLearningが僅差で良かったがAUC 0.89程度</li>
<li>自分でcross validationするようにして色々なmodelerを試したところ、Deep Learningも良かったがGradient Boosted TreesがAUC 0.90と最強だった</li>
<li>なのでGBoostでparameter tuningを。number of treesはdefaultの20からぐっと増やした方が。max depthはちょっとでも大きすぎるとダメ。learning rateもちょっとでも増やすと精度は落ちる</li>
<li>あんまり細かくtuningしても、結局randomizeの影響が大きい。小数点以下3桁程度のぶれは出てしまう。即ち、全く同じparametersで試しても結果が違う。reproducibleをcheckしても、cross validationの仕方が違うので、全てのrandom性を注意深く固定しないとならないし、randomのseedを探索する事になってしまうのもアホらしい</li>
<li>仮にmodelingが出来たとして、これをserviceとして抜き出すのは難しそう。RapidMiner Serverを買えということか。そういうところで彼らは商売をしているのだろう。</li>
<li>GPUが無くても速い(30秒程度)のは、MultiThreadを使っているからか。<code>top</code>を見ていると気持ちいいくらいmulti coresを使っている。流石はJavaである。</li>
<li>よく言われる<code>XGBoost</code>というmodelerは無く、<code>Gradient Boosted Trees</code>がそれ相当</li>
<li>one-hot vector化しようと思って<code>Nominal to Numerical</code>を前処理に入れたら精度が落ちた。その出力をよく見たら、これ単に非numericalなattributesを落としてるだけ。何これ。じゃぁっていうんで<code>Nominal to Binomial</code>にしてみても全く同じ。えー、RapidMinerではone-hot vector化、簡単に出来ないの!? 他の言語ではチョー簡単なのに。</li>
<li>RapidMiner、凄く簡単ですけど、これはinput dataがone fileで数万recordsしか無いから、でしょう。これが画像群だったらこうはいかないでしょう。</li>
</ul>
<h3>現時点で最良の結果(5/11/2018現在68位)</h3>
<p>https://signate.jp/competitions/1/leaderboard#scoreboard</p>
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class='html'><span class='line'>number of trees: 205
</span><span class='line'>maximal depth: 5
</span><span class='line'>min rows: 10.0
</span><span class='line'>min split improvement: 0.0
</span><span class='line'>number of bins: 20
</span><span class='line'>learning rate: 0.1
</span><span class='line'>sample rate: 0.8
</span><span class='line'>
</span><span class='line'>PerformanceVector:
</span><span class='line'>accuracy: 90.89% +/- 0.42% (mikro: 90.89%)
</span><span class='line'>ConfusionMatrix:
</span><span class='line'>True:	1	0
</span><span class='line'>1:	1638	935
</span><span class='line'>0:	1536	23019
</span><span class='line'>AUC: 0.933 +/- 0.006 (mikro: 0.933) (positive class: 0)
</span></code></pre></td></tr></table></div></figure>
<p>これ以上AUCを上げるには、
RapidMinerじゃない何か、RかPythonを使って、
入力dataもone-hot vector化して、とかしないとならないような気がします。</p>
]]></content></entry><entry><title type="html"><![CDATA[Easy AI APIs]]></title><link href="http://u-ryo.github.io//blog/2017/08/23/easy-ai-apis/"/><updated>2017-08-23T10:12:53+09:00</updated><id>/blog/2017/08/23/easy-ai-apis/</id><content type="html"><![CDATA[<p><a href="http://programming-study.com/trouble/ai5/">誰でも簡単に人工知能を使えるサービスがヤバすぎる！</a></p>
<p>この辺の技術は、変化が激しいのでその時々で十分に調査する必要がありますね。
それにしても、随分簡単に使えそうになっていますね。
自分でやってみないと、何とも言えませんが...</p>
]]></content></entry></feed>