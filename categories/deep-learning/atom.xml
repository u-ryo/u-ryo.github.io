<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><title><![CDATA[u-ryo's blog]]></title><link href="http://u-ryo.github.io//categories/deep-learning/atom.xml" rel="self"/><link href="http://u-ryo.github.io//"/><updated>2018-07-18T07:36:11+09:00</updated><id>http://u-ryo.github.io//</id><author><name><![CDATA[u-ryo]]></name></author><generator uri="http://sysgears.com/grain/">Grain</generator><entry><title type="html"><![CDATA[Deeplooks]]></title><link href="http://u-ryo.github.io//blog/2019/01/24/deeplooks/"/><updated>2019-01-24T04:57:31+09:00</updated><id>/blog/2019/01/24/deeplooks/</id><content type="html"><![CDATA[<p><a href="https://deeplooks.com/">Deeplooks</a>という、
顔の良さ?を冷厳に判定するsiteがあるのを知りました。
アプリとかだと顔のpartsの対称性や黄金比などから算出するみたいですが、
これはdeep learningの蓄積によるものだと。
試してみると、ぼくの写真ではどうやっても2.5〜2.7がせいぜい。
同じ写真でも拡大率によって2.5〜2.7の間でぶれますね。
笑顔など表情では変わらないようです。
また、女性の方が高めに出るようです。
なので、0.2程度は誤差があるものと。
それにしても、ぼく如きでは3とか4は出そうにありません。
確かに「この人美人だなぁ」という人を入れれば高得点なので、
客観的指標になりそうです。
Deeplooksのスマホアプリはないですが、
普通にbrowserでaccessすれば、その場で撮った写真で判定できるので十分です。
ただこれ、submitした写真は蓄積されていくようで、しまった!</p>
]]></content></entry></feed>